import numpy as np

# Step 1: Define the problem
def objective_function(x):
    """Example function: Sphere function (sum of squares). Replace with your function."""
    return sum(x**2)

# Step 2: Initialize parameters
def grey_wolf_optimizer(obj_func, dim, lb, ub, wolves_count, max_iter):
    """
    Parameters:
    - obj_func: The objective function to minimize.
    - dim: Number of dimensions.
    - lb, ub: Lower and upper bounds of the search space (can be scalars or lists).
    - wolves_count: Number of wolves in the population.
    - max_iter: Number of iterations.
    """
    
    # Ensure bounds are lists
    if isinstance(lb, (int, float)):
        lb = [lb] * dim
    if isinstance(ub, (int, float)):
        ub = [ub] * dim

    # Step 3: Initialize population
    wolves_positions = np.random.uniform(lb, ub, (wolves_count, dim))
    wolves_fitness = np.array([obj_func(wolf) for wolf in wolves_positions])

    # Initialize Alpha, Beta, and Delta
    alpha_pos = wolves_positions[0]
    beta_pos = wolves_positions[1]
    delta_pos = wolves_positions[2]
    alpha_fit, beta_fit, delta_fit = float("inf"), float("inf"), float("inf")

    # Step 4: Optimization loop
    for t in range(max_iter):
        # Evaluate fitness and update Alpha, Beta, Delta wolves
        for i in range(wolves_count):
            fitness = obj_func(wolves_positions[i])
            if fitness < alpha_fit:
                alpha_fit, alpha_pos = fitness, wolves_positions[i].copy()
            elif fitness < beta_fit:
                beta_fit, beta_pos = fitness, wolves_positions[i].copy()
            elif fitness < delta_fit:
                delta_fit, delta_pos = fitness, wolves_positions[i].copy()

        # Update positions
        a = 2 - 2 * t / max_iter  # Linearly decreasing component
        for i in range(wolves_count):
            for j in range(dim):
                # Update positions relative to alpha, beta, and delta
                r1, r2 = np.random.rand(), np.random.rand()
                A1, C1 = 2 * a * r1 - a, 2 * r2
                D_alpha = abs(C1 * alpha_pos[j] - wolves_positions[i][j])
                X1 = alpha_pos[j] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2, C2 = 2 * a * r1 - a, 2 * r2
                D_beta = abs(C2 * beta_pos[j] - wolves_positions[i][j])
                X2 = beta_pos[j] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3, C3 = 2 * a * r1 - a, 2 * r2
                D_delta = abs(C3 * delta_pos[j] - wolves_positions[i][j])
                X3 = delta_pos[j] - A3 * D_delta

                # New position is the average of the three influences
                wolves_positions[i][j] = (X1 + X2 + X3) / 3

            # Apply bounds
            wolves_positions[i] = np.clip(wolves_positions[i], lb, ub)

    # Step 7: Output the best solution
    return alpha_pos, alpha_fit

# Example usage
if __name__ == "__main__":
    dim = 5  # Number of dimensions
    lb = -10  # Lower bound
    ub = 10   # Upper bound
    wolves_count = 20  # Population size
    max_iter = 50  # Number of iterations

    best_position, best_fitness = grey_wolf_optimizer(objective_function, dim, lb, ub, wolves_count, max_iter)
    print("Best Position:", best_position)
    print("Best Fitness:", best_fitness)
